{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modelo de Machine Learning** para predecir la ESPERANZA DE VIDA en un país determinado a partir de diferentes indicadores asociados a economía, educación, salud y desarrollo social."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos a trabajar en el desarrollo del modelo de machine learning. \n",
    "En una primera parte realizaremos el análisis exploratorio de los datos para quedarnos con un dataset limpio y ordenado, seleccionando aquellas variables que nos permita realizar un modelado adecuado. \n",
    "Luego procederemos a entrenar el modelo y por último realizaremos las evaluaciones pertinentes sobre el resultado de nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos algunas de las librerías a utilizar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leemos el archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos el archivo que vamos a trabajar, el mismo proviene del proceso de ETL realizado previamente y refiere a la tabla de Hechos definida en nuestra base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('facts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos la cantidad de nulos que tenemos por cada variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_null = data[data['value'].isna()]\n",
    "series = data_null['series_id'].unique()\n",
    "countries = data_null['country_id'].unique()\n",
    "naSummary = pd.DataFrame(columns=['country_id','series','#NaN'])\n",
    "for c in countries:\n",
    "    df_facts_null_c = data_null[data_null['country_id']==c]\n",
    "    for s in series:\n",
    "        df_facts_null_cs = df_facts_null_c[df_facts_null_c['series_id']==s]\n",
    "        l = sum(df_facts_null_cs['value'].isna())\n",
    "        if l > 0:\n",
    "            naSummary = pd.concat([naSummary,pd.DataFrame([[c,s,l]],columns=['country_id','series','#NaN'])],ignore_index=True)\n",
    "\n",
    "naSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total de nulos\n",
    "naSummary['#NaN'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupamos los datos nulos por variable y pais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naSummary.groupby('series').sum().sort_values('#NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que 19 de las 20 variables con las que contamos contienen valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con las variables que tienen menos de 30 nulos por pais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naSummaryLess10 = naSummary[naSummary['#NaN']<30]\n",
    "naSummaryLess10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total de nulos actuales\n",
    "naSummaryLess10['#NaN'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputación de valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección procederemos a imputar los valores nulos utilizando el modelo ARIMA (AutoRegressive Integrated Moving Average) el mismo es un modelo estadístico ampliamente utilizado para analizar y predecir series temporales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como contamos con un dataset con relativamente pocos años de análisis, consideramos aumentar la cantidad de años para combinarlo con el dataset utilizado hasta aqui y lograr una mejor performance del modelo ARIMA y así obtener mejores predicciones para nuestras imputaciones. Para esto se creo una tabla en la sección de ETL con datos desde el año 1960 a utilizar a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_60 = pd.read_csv('facts_1960.csv')\n",
    "data_60.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cantidad de nulos previamente:', data_60.value.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procedemos a trabajar con el modelo ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import numpy as np\n",
    "for i in range(len(naSummaryLess10)):\n",
    "    c = naSummaryLess10.iloc[i,0]\n",
    "    s = naSummaryLess10.iloc[i,1]\n",
    "    df_facts_cs = data_60[(data_60['country_id']==c)&(data_60['series_id']==s)]\n",
    "\n",
    "    #print(df_facts_cs)\n",
    "    \n",
    "    y = df_facts_cs['value'].values\n",
    "    ARIMAmodel = ARIMA(y, order = (1, 0, 1))\n",
    "    ARIMAmodel = ARIMAmodel.fit()\n",
    "\n",
    "    indexNaN = df_facts_cs[df_facts_cs['value'].isna()].index\n",
    "    for j in indexNaN:\n",
    "        year = int(df_facts_cs.loc[j,'year'])\n",
    "        if year >= 1993:\n",
    "            x = year - 1960\n",
    "            y_pred = ARIMAmodel.predict(x)\n",
    "            #print('Imputation on country: ',c,', series: ',s,', year: ',str(year),' and value: ',y_pred[0])\n",
    "\n",
    "            df_facts_cs.loc[j,'value'] = y_pred[0]\n",
    "\n",
    "    data_60[(data_60['country_id']==c)&(data_60['series_id']==s)] = df_facts_cs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('cantidad de nulos posteriormente:', data_60.value.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = [\"GC.XPN.TOTL.GD.ZS\", \"NE.RSB.GNFS.CD\", \"NY.GDP.MKTP.KD.ZG\", \"NY.GDP.PCAP.CD\",\n",
    "                \"NY.GNP.PCAP.CD\", \"SE.XPD.TOTL.GD.ZS\", \"SE.XPD.PRIM.PC.ZS\", \"SE.ADT.LITR.ZS\",\n",
    "                \"SH.XPD.GHED.GD.ZS\", \"SP.DYN.LE00.IN\", \"SH.DYN.NMRT\", \"SH.DYN.MORT\",\n",
    "                \"SN.ITK.DEFC.ZS\", \"IP.PAT.RESD\", \"GB.XPD.RSDV.GD.ZS\", \"SP.POP.SCIE.RD.P6\",\n",
    "                \"SI.POV.GINI\", \"VC.IHR.PSRC.P5\", \"SI.POV.NAHC\", \"SL.UEM.TOTL.ZS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequeamos los nulos resultantes por variable y pais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_30 = data_60[data_60['year'].astype(int)>=1993]\n",
    "data_null = data_30[data_30['value'].isna()]\n",
    "series = data_null['series_id'].unique()\n",
    "countries = data_null['country_id'].unique()\n",
    "naSummary = pd.DataFrame(columns=['country_id','series','#NaN'])\n",
    "for c in countries:\n",
    "    data_null_c = data_null[data_null['country_id']==c]\n",
    "    for s in series:\n",
    "        data_null_cs = data_null_c[data_null_c['series_id']==s]\n",
    "        l = sum(data_null_cs['value'].isna())\n",
    "        if l > 0:\n",
    "            naSummary = pd.concat([naSummary,pd.DataFrame([[c,s,l]],columns=['country_id','series','#NaN'])],ignore_index=True)\n",
    "\n",
    "for i in indicators:\n",
    "    if i not in naSummary['series'].values:\n",
    "        naSummary = pd.concat([naSummary,pd.DataFrame([['',i,0]],columns=['country_id','series','#NaN'])],ignore_index=True)\n",
    "\n",
    "naSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total de nulos luego de imputar\n",
    "naSummary['#NaN'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos cuales variables nos han quedado sin valores nulos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naSummary.groupby('series').sum().sort_values('#NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraemos las series sin nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_sin_nulos = naSummary[naSummary['#NaN'] == 0]['series'].tolist()\n",
    "\n",
    "# Muestra las series sin nulos\n",
    "series_sin_nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos graficamente los datos con y sin imputación para observar los cambios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_60_NaN = pd.read_csv('facts_1960.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filtrar los datos para la serie y país específicos\n",
    "serie = 'GC.XPN.TOTL.GD.ZS'\n",
    "pais = 'ARG'\n",
    "data_serie = data_60[(data_60['series_id'] == serie) & (data_60['country_id'] == pais)]\n",
    "data_serie_nan = data_60_NaN[(data_60_NaN['series_id'] == serie) & (data_60_NaN['country_id'] == pais)]\n",
    "\n",
    "# Crear el gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_serie['year'], data_serie['value'], label='data_60')\n",
    "plt.plot(data_serie_nan['year'], data_serie_nan['value'], label='data_60_NaN', linestyle='dashed', color='red')\n",
    "\n",
    "# Agregar etiquetas y leyenda\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Value')\n",
    "plt.title(f'Comparación de la serie {serie} para {pais}')\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se pudo observar, de las 19 variables que contenían valores nulos antes de las imputaciones, sólo nos han quedado 8. Esto nos permite llevar la cantidad de variables aptas para consumir por el modelo de predicción de 1 a 12. Consideramos que es una cantidad de datos adecuada para obtener resultados satisfactorios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconfiguración del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa, la estructura del dataframe no es el más adecuado para el modelado que queremos realizar, por lo tanto procedemos a darle una estructura más óptima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las filas que corresponden a las series sin nulos\n",
    "data_filtrado = data_30[data_30['series_id'].isin(series_sin_nulos)]\n",
    "\n",
    "# Crear una tabla pivote\n",
    "data = data_filtrado.pivot_table(index=['country_id', 'year'], columns='series_id', values='value').reset_index()\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos los nombres a las variables para identificarlas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres = {\n",
    "    'GC.XPN.TOTL.GD.ZS': 'Gasto(%_PIB)',\n",
    "    'NE.RSB.GNFS.CD': 'Bal_comercial(US$)',\n",
    "    'NY.GDP.MKTP.KD.ZG': 'PIB_crec(%_anual)',\n",
    "    'NY.GDP.PCAP.CD': 'PIB_per_cap(US$)',\n",
    "    'NY.GNP.PCAP.CD':'INB_per_cap(US$)',\n",
    "    'SE.XPD.TOTL.GD.ZS':'Educacion(%_PIB)',\n",
    "    'SE.XPD.PRIM.PC.ZS':'Gasto_alumno_primaria(%_PIB_per_capita)',\n",
    "    'SE.ADT.LITR.ZS':'Tasa_alfabetizacion_adultos(%15_años_o_mas)',\n",
    "    'SH.XPD.GHED.GD.ZS':'Salud(%_PIB)',\n",
    "    'SP.DYN.LE00.IN':'EDV',\n",
    "    'SH.DYN.NMRT':'Mortalidad_neo',\n",
    "    'SH.DYN.MORT':'Mortalidad_5',\n",
    "    'SN.ITK.DEFC.ZS':'Desnutricion(%_poblacion)',\n",
    "    'IP.PAT.RESD':'Patentes',\n",
    "    'GB.XPD.RSDV.GD.ZS':'I+D(%_PIB)',\n",
    "    'SP.POP.SCIE.RD.P6':'Investigadores',\n",
    "    'SI.POV.GINI':'Gini',\n",
    "    'VC.IHR.PSRC.P5':'Homicidios',\n",
    "    'SI.POV.NAHC':'Pobreza',\n",
    "    'SL.UEM.TOTL.ZS':'Desempleo',\n",
    "    'year':'Año',\n",
    "    'country_id':'Pais_id'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar las columnas utilizando el método rename\n",
    "data.rename(columns=nombres, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportamos la tabla resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('tabla_ML.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de correlación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Gráfico general**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.drop(['Pais_id'], axis=1).corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Correlación de la variable objetivo 'EDV' con las variables predictoras:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = corr.corr()\n",
    "correlation_with_edv = correlation_matrix['EDV'].sort_values(ascending=False)\n",
    "print(\"Correlación con 'EDV':\")\n",
    "print(correlation_with_edv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación de la correlación con 'EDV':**\n",
    "\n",
    "- Se observa una correlación positiva fuerte con variables como 'PIB_per_cap(US$)', 'INB_per_cap(US$)', 'Salud(%_PIB)', y 'Año'. Esto sugiere que a medida que estas variables aumentan, la esperanza de vida ('EDV') tiende a aumentar.\n",
    "- Hay correlaciones negativas fuertes con 'Homicidios', 'Mortalidad_neo', y 'Mortalidad_5'. Esto indica que a medida que estas variables aumentan, la esperanza de vida tiende a disminuir.\n",
    "- Ambos análisis son a piori lógicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Correlacion entre variables independientes:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se observa una alta correlación entre dos pares de variables, lo cual conlleva riesgo de MULTICOLINEALIDAD.**\n",
    "\n",
    "- Respecto a las variables asociadas a las tasas de mortalidad en niños y neonatales se decide quedarse con la primera ya que esta incluye a la otra. \n",
    "- En el caso de las variables asociadas al PBI la interpretación conceptual sugiere que miden aspectos diferentes del PIB, podría tener sentido incluir ambas variables en el modelo de regresión lineal ya que podrían ser importantes para explicar la variabilidad en la EDV. Por ello se realiza un análisis más profundo antes de tomar una decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos la correlación simple entre ambas variables\n",
    "correlation = data[['PIB_crec(%_anual)', 'PIB_per_cap(US$)']].corr()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los resultados de la correlación simple entre las variables \"PIB_crec(%_anual)\" y \"PIB_per_cap(US$)\", observamos que la correlación es relativamente baja, con un valor de aproximadamente -0.106. Este valor cercano a cero indica una correlación débil entre las dos variables.\n",
    "\n",
    "La baja correlación sugiere que estas dos variables no están fuertemente relacionadas linealmente. En este caso, es menos probable que la multicolinealidad sea un problema significativo entre estas dos variables. \n",
    "\n",
    "Sin embargo, para obtener una evaluación más completa de la multicolinealidad, se procede a calcular los factores de inflación de la varianza (VIF)\n",
    "para confirmar la ausencia de multicolinealidad significativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "variables = data[['PIB_crec(%_anual)', 'PIB_per_cap(US$)']]\n",
    "\n",
    "# Agrega una constante para calcular el VIF\n",
    "variables['constante'] = 1\n",
    "\n",
    "# Calcula el VIF para cada variable\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = variables.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(variables.values, i) for i in range(variables.shape[1])]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de los Factores de Inflación de la Varianza (VIF) muestran que los valores son relativamente bajos para ambas variables, \"PIB_crec(%_anual)\" y \"PIB_per_cap(US$)\", con valores de alrededor de 1.01. En general, VIF cercanos a 1 indican que no hay una alta multicolinealidad entre las variables.\n",
    "\n",
    "Además, el VIF de la constante es de aproximadamente 2.85, lo cual es bastante bajo. El VIF de la constante indica cuánto se infla la varianza de los coeficientes debido a la multicolinealidad, y valores bajos son deseables.\n",
    "\n",
    "Dado que los VIF son bajos en este caso, no parece haber una multicolinealidad significativa entre las variables \"PIB_crec(%_anual)\" y \"PIB_per_cap(US$)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definimos la variable a predecir (Y) y las variables predictoras (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"EDV\"]\n",
    "x = data.drop(['EDV','Pais_id','Mortalidad_neo'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detección de outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se analiza las variables en búsqueda de posibles valores atípicos que puedan generar inconvenientes en nuestros resultados. Observamos en un primer análisis gráficos de caja, los cuales nos ofrecen una rápida muestra visual de la distribución de los valores de cada variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Número de variables\n",
    "num_variables = len(x.columns)\n",
    "\n",
    "# Número de filas y columnas para organizar los gráficos\n",
    "num_rows = num_variables // 3 + (num_variables % 3 > 0)\n",
    "num_cols = 3\n",
    "\n",
    "# Crea subgráficos\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 4 * num_rows))\n",
    "fig.suptitle('Boxplots de Variables Predictoras', y=1.02)\n",
    "\n",
    "# Itera sobre las variables y crea los boxplots\n",
    "for i, (variable, ax) in enumerate(zip(x.columns, axes.flatten())):\n",
    "    sns.boxplot(x=x[variable], ax=ax)\n",
    "    ax.set_title(f'{variable}')\n",
    "\n",
    "# Ajusta el diseño para evitar solapamiento\n",
    "plt.tight_layout()\n",
    "\n",
    "# Muestra la visualización\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Si bien se observan en la mayoría de las variables algunos valores alejados del rango intercuartílico, esto puede tener sentido y no se sería apropiado en un primer análisis descartarlos. Hay que recordar que nuestro dataset se compone de paises muy variados en todos los términos de los factores observados por lo cual es esperable encontrar una amplia variabilidad en los datos debido a las diferencias naturales entre las entidades estudiadas, esto además puedo enriquecer a nuestro modelo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, antes de quedarnos completamente con esa conclusión, analizaremos con mayor detalle algunas variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Educación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis Estadístico:**\n",
    "\n",
    "Utilizamos medidas estadísticas como el rango intercuartílico (IQR) para identificar outliers.\n",
    "Definimos umbrales para identificar valores atípicos. Los valores que están por debajo de Q1 - 1.5 * IQR o por encima de Q3 + 1.5 * IQR podrían considerarse outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el rango intercuartílico (IQR) para 'Educacion(%_PIB)'\n",
    "Q1_educacion = x['Educacion(%_PIB)'].quantile(0.25)\n",
    "Q3_educacion = x['Educacion(%_PIB)'].quantile(0.75)\n",
    "IQR_educacion = Q3_educacion - Q1_educacion\n",
    "\n",
    "# Define umbrales para identificar outliers en 'Educacion(%_PIB)'\n",
    "lower_bound_educacion = Q1_educacion - 1.5 * IQR_educacion\n",
    "upper_bound_educacion = Q3_educacion + 1.5 * IQR_educacion\n",
    "\n",
    "# Identifica outliers en 'Educacion(%_PIB)'\n",
    "outliers_educacion = (x['Educacion(%_PIB)'] < lower_bound_educacion) | (x['Educacion(%_PIB)'] > upper_bound_educacion)\n",
    "\n",
    "# Filtra los outliers en 'x' y obtén los correspondientes datos de 'y' (esperanza de vida)\n",
    "outliers_data = data[outliers_educacion]\n",
    "outliers_paises_anios = outliers_data[['Pais_id', 'Año']]\n",
    "\n",
    "# Muestra los registros atípicos y a qué país y años corresponden\n",
    "print(\"Registros Atípicos en 'Educacion(%_PIB)':\")\n",
    "outliers_data[['Pais_id', 'Año','Educacion(%_PIB)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crea un boxplot de la variable 'Educacion' después de Winsorizing\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x['Educacion(%_PIB)'])\n",
    "plt.title('Boxplot de la Variable \"Educacion(%_PIB)\" antes de Winsorizing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "# Define los límites de Winsorizing (ajusta según tu preferencia)\n",
    "lower_limit = 0.05\n",
    "upper_limit = 0.05\n",
    "\n",
    "# Aplica Winsorizing a la variable 'Educacion'\n",
    "x['Educacion(%_PIB)'] = winsorize(x['Educacion(%_PIB)'], limits=[lower_limit, upper_limit])\n",
    "\n",
    "# Puedes ajustar los límites según tu necesidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crea un boxplot de la variable 'Educacion' después de Winsorizing\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x['Educacion(%_PIB)'])\n",
    "plt.title('Boxplot de la Variable \"Educacion(%_PIB)\" después de Winsorizing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de la variable Educación, se puede observar que la gran mayoría de los datos por encima del máximo del boxplot corresponden a Cuba, indicando que el país ha invertido en Educación mucho más que el resto de los paises observados. Descartarndo estos valores perderíamos esa información que puede resultar valiosa para el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homicidios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el rango intercuartílico (IQR) para 'Homicidios'\n",
    "Q1_homicidios = x['Homicidios'].quantile(0.25)\n",
    "Q3_homicidios = x['Homicidios'].quantile(0.75)\n",
    "IQR_homicidios = Q3_homicidios - Q1_homicidios\n",
    "\n",
    "# Define umbrales para identificar outliers en 'Homicidios'\n",
    "lower_bound_homicidios = Q1_homicidios - 1.5 * IQR_homicidios\n",
    "upper_bound_homicidios = Q3_homicidios + 1.5 * IQR_homicidios\n",
    "\n",
    "# Identifica outliers en 'Homicidios'\n",
    "outliers_homicidios = (x['Homicidios'] < lower_bound_homicidios) | (x['Homicidios'] > upper_bound_homicidios)\n",
    "\n",
    "# Filtra los outliers en 'x' y obtén los correspondientes datos de 'y' (esperanza de vida)\n",
    "outliers_data_homicidios = data[outliers_homicidios]\n",
    "outliers_paises_anios_homicidios = outliers_data_homicidios[['Pais_id', 'Año']]\n",
    "\n",
    "# Muestra los registros atípicos y a qué país y años corresponden\n",
    "print(\"Registros Atípicos en 'Homicidios':\")\n",
    "outliers_data_homicidios[['Pais_id', 'Año','Homicidios']].sample(40, random_state=126).sort_values(by='Homicidios', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se analizaron los outliers en la variable 'Homicidios' y al igual que eduación, se observa que los valores si bien estan alejados del rango intercuartílico se explica desde la naturaleza de las observaciones. En este caso la mayoría de los valores por encima del maximo corresponde a El Salvador, un país que se conoce por una alta tasa de homicidios intencionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Con esto reafirmamos la desición de mantener todos los valores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state =123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tamaño del set de train',x_train.shape)\n",
    "print('Tamaño del set de test:',x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos los valores estadísticos previo al escalamiento\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos la librería de sklearn para escalar nuestras variables predictoras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "esc = StandardScaler()\n",
    "\n",
    "x_train_esc = esc.fit_transform(x_train)\n",
    "x_test_esc = esc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo utilizando la librería sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(x_train_esc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la variable de predicción \n",
    "y_pred = modelo.predict(x_test_esc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validaciones del Modelo de Regresión:\n",
    "Se procede a evaluar si se  con las suposiciones del modelo utilizado\n",
    "\n",
    "- *Linealidad:* entre las variables independientes y la variable dependiente. Utilizamos gráfico de dispersión.\n",
    "\n",
    "- *Independencia:* Asegurar que los errores (residuos) no estén correlacionados entre sí. Examinamos el gráfico de residuos.\n",
    "\n",
    "- *Homocedasticidad:* Verificar que la varianza de los errores sea constante en todos los niveles de las variables independientes. Lo observamos en un gráfico de residuos frente a las predicciones.\n",
    "\n",
    "- *Normalidad de los Residuos:* Comprobar que los residuos sigan una distribución normal. Lo evaluamos mediante un histograma de los residuos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linealidad (Gráfico de Dispersión):\n",
    "\n",
    "- Un gráfico simple donde el eje x representa los valores reales y el eje y representa las predicciones.\n",
    "- Vemos cómo se alinean las predicciones con los valores reales. \n",
    "- Si la relación entre las variables es lineal, deberíamos ver una dispersión uniforme alrededor de la línea diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Gráfico de Dispersión: Valores Reales vs. Predicciones')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independencia (Gráfico de Residuos):\n",
    "\n",
    "- Un gráfico que muestra la diferencia entre los valores reales y las predicciones en función de los valores reales.\n",
    "- Podemos identificar patrones en los residuos y verificar si hay heterocedasticidad.\n",
    "- Deberían distribuirse aleatoriamente alrededor de la línea horizontal cero. No debería haber un patrón discernible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_pred\n",
    "plt.scatter(y_test, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Residuos')\n",
    "plt.title('Gráfico de Residuos')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homocedasticidad (Gráfico de Residuos vs. Predicciones):\n",
    "\n",
    "- Aquí, buscamos una dispersión constante de los residuos en todos los niveles de las predicciones. \n",
    "- No debería haber un patrón en forma de cono o embudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicciones (y_pred)')\n",
    "plt.ylabel('Residuos')\n",
    "plt.title('Gráfico de Residuos vs. Predicciones')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograma de residuos:\n",
    "\n",
    "- Un histograma que muestra la distribución de los residuos.\n",
    "- Puedes verificar si los residuos siguen una distribución normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(residuals, bins=30)\n",
    "plt.xlabel('Residuos')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Histograma de Residuos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se pudo validar todas las suposiciones del modelo de regresión lineal, por lo tanto se procede a evaluar las métricas de los resultados obtenido en el modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de desempeño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Error Absoluto Medio (MAE):**\n",
    "\n",
    "- El MAE mide el promedio de las diferencias absolutas entre las predicciones y los valores reales.\n",
    "- Cuanto más bajo sea el MAE, mejor será el rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'MAE: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calcula los errores absolutos\n",
    "mae_errors = np.abs(y_test - y_pred)\n",
    "\n",
    "# Gráfico de dispersión de MAE\n",
    "plt.scatter(y_test, mae_errors)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Valores Reales (y_test)')\n",
    "plt.ylabel('Errores Absolutos')\n",
    "plt.title('Gráfico de Dispersión: Valores Reales vs. Errores Absolutos (MAE)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El MAE (Error Absoluto Medio) de 1.1977 significa que, en promedio, las predicciones de esperanza de vida difieren en aproximadamente 1.2 años de los valores reales**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien el resultado ya parece ser muy bueno, para obtener una evaluación más efectiva de este resultado la llevaremos a nuestro contexto, haciendo una comparación con la magnitud de la EDV en nuestro conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_life_expectancy = y_test.mean()\n",
    "std_life_expectancy = y_test.std()\n",
    "\n",
    "print(f'Media de Esperanza de Vida: {mean_life_expectancy:.2f} años')\n",
    "print(f'Desviación Estándar de Esperanza de Vida: {std_life_expectancy:.2f} años')\n",
    "\n",
    "mae_percentage_of_mean = (mae / mean_life_expectancy) * 100\n",
    "\n",
    "print(f'MAE como porcentaje de la Media: {mae_percentage_of_mean:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación:**\n",
    "\n",
    "- El MAE del 1.57% sugiere que, en promedio, las predicciones son bastante precisas en relación con la magnitud de la esperanza de vida en tu conjunto de datos.\n",
    "- En el contexto de la esperanza de vida, un MAE del 1.55% podría considerarse como un buen desempeño, especialmente si la variabilidad natural de la esperanza de vida en nuestro conjunto de datos es mayor que este porcentaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Error Cuadrático Medio (MSE):**\n",
    "\n",
    "- El MSE mide el promedio de los cuadrados de las diferencias entre las predicciones y los valores reales.\n",
    "- Penaliza errores más grandes más fuertemente que el MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'MSE: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como el valor del MAE, el MSE es realtivamente pequeño respecto a la media de EVD, afirma el buen desempeño de nuestro modelo de predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RMSE (Raíz del Error Cuadrático Medio):**\n",
    "\n",
    "- El RMSE es simplemente la raíz cuadrada del MSE.\n",
    "- Es más interpretable que el MSE ya que proporciona una medida del error en la misma escala que la variable dependiente. Cuanto más cercano a cero, mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Coeficiente de Determinación (R²):**\n",
    "\n",
    "- El R² indica la proporción de la variabilidad en la variable dependiente que es predecible a partir de las variables independientes.\n",
    "- Un valor más cercano a 1 indica un mejor ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R²: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un (R²) de 0.8977 significa que aproximadamente el 89.77% de la variabilidad en la esperanza de vida es explicada por las variables independientes incluidas en el modelo.\n",
    "\n",
    "- **Interpretación:** Un (R²) de 0.8977 es bastante alto y sugiere que el modelo está capturando bien las tendencias y patrones en los datos de esperanza de vida. Casi el 90% de la variabilidad en la esperanza de vida se puede explicar mediante las variables incluidas en el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONCLUSIÓN: se evaluó el desempeño del modelo a través de distintas métricas y todas arrojan resultados positivos, indicando que nuestro modelo consigue realizar muy buenas predicciones del valor de esperanza de vida esperada.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validación Cruzada (Cross-Validation):**\n",
    "- La validación cruzada k-fold divide el conjunto de datos en k partes (folds) y realiza k iteraciones de entrenamiento y evaluación. En cada iteración, un fold se utiliza como conjunto de prueba y los k-1 folds restantes se utilizan para entrenar el modelo. Esto proporciona k estimaciones de rendimiento que se promedian para obtener una medida general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función que utiliza la validación cruzada y obtiene las métricas de nuestro interés en cada iteración de la validación según el parámetro 'cv'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def cross_val_metrics(estimator, X, y, cv=5):\n",
    "    # Realiza la validación cruzada\n",
    "    y_pred = cross_val_predict(estimator, X, y, cv=cv)\n",
    "\n",
    "    # Calcula las métricas para cada iteración\n",
    "    metrics = []\n",
    "    for i in range(cv):\n",
    "        start = i * len(y) // cv\n",
    "        end = (i + 1) * len(y) // cv\n",
    "        y_true_i = y[start:end]\n",
    "        y_pred_i = y_pred[start:end]\n",
    "\n",
    "        mae_i = mean_absolute_error(y_true_i, y_pred_i)\n",
    "        mse_i = mean_squared_error(y_true_i, y_pred_i)\n",
    "        rmse_i = np.sqrt(mse_i)\n",
    "        r2_i = r2_score(y_true_i, y_pred_i)\n",
    "\n",
    "        metrics.append({'MAE': mae_i, 'MSE': mse_i, 'RMSE': rmse_i, 'R²': r2_i})\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso de la función con nuestro modelo\n",
    "metrics_per_iteration = cross_val_metrics(modelo, x, y, cv=5)\n",
    "\n",
    "# Imprime los resultados para cada iteración\n",
    "for i, metrics in enumerate(metrics_per_iteration, 1):\n",
    "    print(f'Iteración {i}: {metrics}')\n",
    "\n",
    "# Calcula el promedio de cada métrica\n",
    "avg_metrics = {\n",
    "    'MAE': np.mean([m['MAE'] for m in metrics_per_iteration]),\n",
    "    'MSE': np.mean([m['MSE'] for m in metrics_per_iteration]),\n",
    "    'RMSE': np.mean([m['RMSE'] for m in metrics_per_iteration]),\n",
    "    'R²': np.mean([m['R²'] for m in metrics_per_iteration]),\n",
    "}\n",
    "\n",
    "print(f'Promedio de métricas: {avg_metrics}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que si bien hay cierta variabilidad en los resultados siguen siendo buenos resultados. De esta forma validamos el desempeño del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretabilidad del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coeficientes:\")\n",
    "for feature, coef in zip(x.columns, modelo.coef_):\n",
    "    print(f\"{feature}: {coef}\")\n",
    "\n",
    "print(f\"Intercepto: {modelo.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo sin variable 'Año'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = data[\"EDV\"]\n",
    "x2 = data.drop(['EDV','Pais_id','Mortalidad_neo','Año'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2,y2, test_size = 0.3, random_state =123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "esc = StandardScaler()\n",
    "\n",
    "x_train2_esc = esc.fit_transform(x_train2)\n",
    "x_test2_esc = esc.transform(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "modelo2 = LinearRegression()\n",
    "modelo2.fit(x_train2_esc, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = modelo2.predict(x_test2_esc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mae2 = mean_absolute_error(y_test2, y_pred2)\n",
    "mse2 = mean_squared_error(y_test2, y_pred2)\n",
    "rmse2 = np.sqrt(mse2)\n",
    "r22 = r2_score(y_test2, y_pred2)\n",
    "\n",
    "print(f'MAE2: {mae2}')\n",
    "print(f'MSE2: {mse2}')\n",
    "print(f'RMSE2: {rmse2}')\n",
    "print(f'R²2: {r22}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso de la función con nuestro modelo\n",
    "metrics_per_iteration = cross_val_metrics(modelo2, x2, y2, cv=5)\n",
    "\n",
    "# Imprime los resultados para cada iteración\n",
    "for i, metrics in enumerate(metrics_per_iteration, 1):\n",
    "    print(f'Iteración {i}: {metrics}')\n",
    "\n",
    "# Calcula el promedio de cada métrica\n",
    "avg_metrics = {\n",
    "    'MAE': np.mean([m['MAE'] for m in metrics_per_iteration]),\n",
    "    'MSE': np.mean([m['MSE'] for m in metrics_per_iteration]),\n",
    "    'RMSE': np.mean([m['RMSE'] for m in metrics_per_iteration]),\n",
    "    'R²': np.mean([m['R²'] for m in metrics_per_iteration]),\n",
    "}\n",
    "\n",
    "print(f'Promedio de métricas: {avg_metrics}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coeficientes:\")\n",
    "for feature, coef in zip(x2.columns, modelo.coef_):\n",
    "    print(f\"{feature}: {coef}\")\n",
    "\n",
    "print(f\"Intercepto: {modelo.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testeo con nuevos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos nuestro modelo en un entorno como en el que se desempeñará"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos como ejemplo una muestra de una fila de nuestros datos\n",
    "n_filas_muestra = 1  \n",
    "x_new = x.sample(n=n_filas_muestra, random_state=126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[x_new.index.values]['EDV'] #traemos el valor de EDV para comparar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función que utiliza nuestro modelo y toma nuevos datos para predecir a partir de estos una EDV esperada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ajusta el scaler con los datos de entrenamiento\n",
    "esc = StandardScaler()\n",
    "esc.fit(x_train)\n",
    "\n",
    "def predecir_esperanza_vida(modelo, scaler, x_train, nuevos_datos):\n",
    "    # Asegura que los nuevos datos tengan los mismos nombres de columnas que los datos de entrenamiento\n",
    "    nuevos_datos.columns = x_train.columns\n",
    "    \n",
    "    # Escala los nuevos datos usando el scaler ajustado con los datos de entrenamiento\n",
    "    nuevos_datos_scaled = scaler.transform(nuevos_datos)\n",
    "    \n",
    "    # Realiza la predicción\n",
    "    prediccion = modelo.predict(nuevos_datos_scaled)\n",
    "    \n",
    "    # Imprime el resultado\n",
    "    print(f\"La esperanza de vida predicha es: {round(prediccion.item(),2)} años\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama a la función con los valores de las variables independientes\n",
    "predecir_esperanza_vida(modelo, esc, x_train, x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función si los nuevos datos de entrena se componen con más de un valor por variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir_esperanza_vida(modelo, scaler, x_train, nuevos_datos):\n",
    "    # Asegúrate de que los nuevos datos tengan los mismos nombres de columnas que los datos de entrenamiento\n",
    "    nuevos_datos.columns = x_train.columns\n",
    "    \n",
    "    # Si hay más de una fila en nuevos_datos, ajusta el scaler con los datos de entrenamiento\n",
    "    if len(nuevos_datos) > 1:\n",
    "        scaler.fit(x_train)\n",
    "    \n",
    "    # Escala los nuevos datos usando el scaler\n",
    "    nuevos_datos_scaled = scaler.transform(nuevos_datos)\n",
    "    \n",
    "    # Realiza la predicción\n",
    "    prediccion = modelo.predict(nuevos_datos_scaled)\n",
    "    \n",
    "    # Imprime el resultado\n",
    "    if len(nuevos_datos) == 1:\n",
    "        print(f\"La esperanza de vida predicha es: {round(prediccion.item(), 2)} años\")\n",
    "    else:\n",
    "        for i, pred in enumerate(prediccion):\n",
    "            print(f\"Para la fila {i + 1}, la esperanza de vida predicha es: {round(pred.item(), 2)} años\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparamos y guardamos nuestro modelo en un archivo consumible por nuestro servidor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos un pipeline para poder correr nuestro modelo en nuestro servidor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(esc, modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corroboramos los resultados\n",
    "pipe.fit(x_train, y_train)\n",
    "pipe.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizamos la librería joblib para guardar nuestro pipeline\n",
    "import joblib\n",
    "joblib.dump(pipe, 'pipe.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pipeline from a file\n",
    "same_pipe = joblib.load('pipe.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_pipe.predict(x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
